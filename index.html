<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Title</title>
</head>
<style>
    body {
        color: #ffad00;;
        background: #1f1e1e;
    }

    #canvasOutput {
        margin: 100px auto;
        display: block;
    }

    #videoInput {
        display: none;
    }

    .title {
        margin: 20px;
        text-align: center;
    }

    .title a {
        color: #ffad00;
    }
    
    .title a:visited {
        color: aqua;
    }

    #warn {
        display: block;
        margin: 0 auto;
    }

    #warn-title {
        margin: 8px;
        text-align: center;
    }
</style>
<body>
<div class="title">基于opencv.js（webassembly）前端人脸跟踪，请允许摄像头访问权限 <a href="https://github.com/QutantumProgrammer/opencv-demo"> source code</a></div>
<div id="warn-title">opencv.js 初始化中</div>
<canvas id="warn" width="200" height="12"></canvas>
<video id="videoInput" width="320" height="240"></video>
<canvas id="canvasOutput"></canvas>
</body>
<script type="text/javascript">
  let opencvReadyPromiseResolve;
  window.opencvReadyPromise = new Promise(resolve => opencvReadyPromiseResolve = resolve);
  window.startRunPromise = new Promise(resolve => window.startRunPromiseResolve = resolve);

  // TODO opencv 初始化状体不符合预期，使用时可能未初始化完毕，需要查看api找出准确时机
  const checkOpencv = async () => {
    if (window.cv.Mat) return;
    await new Promise(resolve => setTimeout(resolve, 20));
    await checkOpencv();
  };
  async function onOpenCvReady() {
    await checkOpencv();
    opencvReadyPromiseResolve();
  }
</script>
<script type="text/javascript">
  const context = document.querySelector('#warn').getContext('2d');
  context.globalCompositeOperation = 'lighter';

  let redRectX = 200;
  let lastTime;
  let mark = 0;
  let frameId;
  const drawWarn = () => {
    if (!lastTime || new Date().getTime() - lastTime > 30) {
      lastTime = new Date().getTime();
      context.clearRect(0, 0, 500, 500);
      const w = 9;

      for (let i = 0; i < 40; i++) {
        context.beginPath();
        context.moveTo(-12 + i * w + mark, 12);
        context.lineTo(-6 + i * w + mark, 12);
        context.lineTo(0 + i * w + mark, 0);
        context.lineTo(-6 + i * w + mark, 0);
        context.closePath();
        context.fillStyle = '#ffad00';
        context.fill();
      }
      if (mark < 7) {
        mark++;
      } else {
        mark = 0;
      }

      context.fillStyle = 'red';
      context.beginPath();
      context.moveTo(redRectX, 12);
      context.lineTo(redRectX + 16, 12);
      context.lineTo(redRectX + 8, 0);
      context.lineTo(redRectX - 8, 0);
      context.closePath();
      context.fillStyle = 'red';
      context.fill();
      redRectX -= 2;
      if (redRectX < -20) {
        redRectX = 200;
      }
    }

    frameId = window.requestAnimationFrame(drawWarn);
  }

  drawWarn();

  window.startRunPromise.then(() => {
    window.cancelAnimationFrame(frameId);
    document.querySelector('#warn').remove();
    document.querySelector('#warn-title').remove();
  });
</script>
<script src="./lib/utils.js" type="text/javascript"></script>
<script>
  // openCV 核心实现
  const utils = new Utils('errorMessage');
  const ZOOM = 3;

  const startCameraAndSetDisplaySize = async () => {
    try {
      const video = document.getElementById('videoInput');
      const streaming = await navigator.mediaDevices.getUserMedia({video: true, audio: false});

      const {width, height} = streaming.getVideoTracks()[0].getSettings();

      let displayWidth = 260;
      
      // 移动端降低分辨率以提升性能
      if (/Android|webOS|iPhone|iPod|BlackBerry/i.test(navigator.userAgent)) displayWidth = 160

      const displayHeight = displayWidth / width * height;
      video.setAttribute('width', displayWidth);
      video.setAttribute('height', displayHeight);

      video.srcObject = streaming;
      video.play();
      return {
        video,
        streaming,
      };
    } catch (err) {
      console.log('摄像头开启错误', err);
      throw err;
    }
  }

  const getClassifier = async () => {
    const classifier = new cv.CascadeClassifier();
    const faceCascadeFile = './haarcascade_frontalface_default.xml';

    return new Promise(resolve => {
      utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
        classifier.load(faceCascadeFile);
        resolve(classifier);
      });
    })
  }

  const clearCVObject = (cvObjects) => {
    cvObjects.forEach(item => item?.delete?.());
  };

  const drawFaceRect = (faces, dst) => {
    for (let i = 0; i < faces.size(); ++i) {
      const { x, y, width, height } = faces.get(i);
      
      const pointLeftTop = new cv.Point(x, y);
      const pointRightBottom = new cv.Point(x + width, y + height);
      cv.rectangle(dst, pointLeftTop, pointRightBottom, [255, 80, 0, 255], 1.2);

      // const pointFont = new cv.Point(face.x, face.y - 10);
      // cv.putText(dst, 'cv: Handsome', pointFont, cv.FONT_HERSHEY_SIMPLEX, .8, [255, 120, 0, 255], 2, cv.LINE_AA);
    }
  };

  let tipRectCount = 0;

  const drawTitleOnCanvas = (faces) => {
    tipRectCount += 1;
    const context = document.getElementById('canvasOutput').getContext('2d');
    for (let i = 0; i < faces.size(); ++i) {
      const { x, y } = faces.get(i);
      // 因为在 openCV 层面使用了缩放 2
      context.font = `bold ${16 * ZOOM}px sans-serif`;
      context.fillStyle = '#ffad00';
      if (tipRectCount % 3 === 0) {
        context.rect(ZOOM * x, ZOOM * (y - 24), ZOOM * 4, ZOOM * 14);
        context.fill();
      }
      context.fillText('Handsome', ZOOM * (x + 8), ZOOM * (y - 10));
    }
  };

  let opencvRunning = false;
  const run = async () => {
    try {
      const {video, streaming} = await startCameraAndSetDisplaySize();
      const {cv} = window;

      const src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      const dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      const gray = new cv.Mat();
      const cap = new cv.VideoCapture(video);
      const faces = new cv.RectVector();

      let classifier = await getClassifier();

      const processVideo = () => {
        if (!streaming) {
          clearCVObject([src, dst, gray, faces, classifier]);
          return;
        }
        const begin = Date.now();
        cap.read(src);
        src.copyTo(dst);
        cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
        // detect faces.
        classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
        drawFaceRect(faces, dst);
        let dSize = new cv.Size(dst.cols * ZOOM, dst.rows * ZOOM);
        cv.resize(dst, dst, dSize, 0, 0, cv.INTER_AREA);
        cv.imshow('canvasOutput', dst);
        drawTitleOnCanvas(faces);
        
        if (!opencvRunning) window.startRunPromiseResolve();
        opencvRunning = true;
        
        const FPS = 30;
        const delay = 1000 / FPS - (Date.now() - begin);
        setTimeout(processVideo, delay);
      }

      setTimeout(processVideo, 0);
    } catch (err) {
      console.log('An error occurred! ' + err);
    }
  };

  (async () => {
    await window.opencvReadyPromise;
    run();
  })();
</script>
<script src="./lib/opencv.js" onload="onOpenCvReady()" type="text/javascript"></script>
</html>
